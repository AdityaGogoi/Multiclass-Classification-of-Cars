{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the data of cars available, we will be predicting the origin of the vehicle i.e. North America, Europe, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Source : https://archive.ics.uci.edu/ml/datasets/Auto+MPG\n",
    "#### Getting Data from File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
      "\n",
      "   origin                   car name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model year\",\"origin\",\"car name\"]\n",
    "cars = pd.read_table(\"auto-mpg.data\", delim_whitespace=True,names=columns)\n",
    "print(cars.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "unique_regions = cars['origin'].unique()\n",
    "print(unique_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variables\n",
    "#### Categorical columns like cylinders and year have to be converted to numeric values so that they can be used to predict origin.\n",
    "#### For this we need to use dummy variables. For different categories of cylinders, we can create the same number of dummy variables and put the values 0 for False and 1 for True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
      "\n",
      "   origin                   car name  cyl_3  cyl_4  cyl_5  cyl_6  cyl_8  \\\n",
      "0       1  chevrolet chevelle malibu    0.0    0.0    0.0    0.0    1.0   \n",
      "1       1          buick skylark 320    0.0    0.0    0.0    0.0    1.0   \n",
      "2       1         plymouth satellite    0.0    0.0    0.0    0.0    1.0   \n",
      "3       1              amc rebel sst    0.0    0.0    0.0    0.0    1.0   \n",
      "4       1                ford torino    0.0    0.0    0.0    0.0    1.0   \n",
      "\n",
      "   cyl_3  cyl_4  cyl_5  cyl_6  cyl_8  \n",
      "0    0.0    0.0    0.0    0.0    1.0  \n",
      "1    0.0    0.0    0.0    0.0    1.0  \n",
      "2    0.0    0.0    0.0    0.0    1.0  \n",
      "3    0.0    0.0    0.0    0.0    1.0  \n",
      "4    0.0    0.0    0.0    0.0    1.0  \n",
      "    mpg  displacement horsepower  weight  acceleration  model year  origin  \\\n",
      "0  18.0         307.0      130.0  3504.0          12.0          70       1   \n",
      "1  15.0         350.0      165.0  3693.0          11.5          70       1   \n",
      "2  18.0         318.0      150.0  3436.0          11.0          70       1   \n",
      "3  16.0         304.0      150.0  3433.0          12.0          70       1   \n",
      "4  17.0         302.0      140.0  3449.0          10.5          70       1   \n",
      "\n",
      "                    car name  cyl_3  cyl_4   ...     year_73  year_74  \\\n",
      "0  chevrolet chevelle malibu    0.0    0.0   ...         0.0      0.0   \n",
      "1          buick skylark 320    0.0    0.0   ...         0.0      0.0   \n",
      "2         plymouth satellite    0.0    0.0   ...         0.0      0.0   \n",
      "3              amc rebel sst    0.0    0.0   ...         0.0      0.0   \n",
      "4                ford torino    0.0    0.0   ...         0.0      0.0   \n",
      "\n",
      "   year_75  year_76  year_77  year_78  year_79  year_80  year_81  year_82  \n",
      "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix='cyl')\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "print(cars.head())\n",
    "\n",
    "dummy_years = pd.get_dummies(cars[\"model year\"],prefix=\"year\")\n",
    "cars=pd.concat([cars,dummy_years],axis=1)\n",
    "cars = cars.drop(\"year\",axis=1)\n",
    "cars = cars.drop(\"cylinders\",axis=1)\n",
    "print(cars.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification\n",
    "#### We will use the one-versus-all classification method, which is basically multiple-binary classifications.\n",
    "#### We will split our dataset into training and test set based on ranomizing the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffled_rows = np.random.permutation(cars.index)\n",
    "shuffled_cars = cars.iloc[shuffled_rows]\n",
    "highest_train_row = int(cars.shape[0] * .70)\n",
    "train = shuffled_cars.iloc[0:highest_train_row]\n",
    "test = shuffled_cars.iloc[highest_train_row:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a multiclass Logistics Regression Model\n",
    "#### We are basically dividing our multi-class model into 3 binary models:\n",
    "#### 1. Where all cars built in North America ar 1 and other origins are 0.\n",
    "#### 2. Where all cars built in Europe ar 1 and other origins are 0.\n",
    "#### 3. Where all cars built in Asia ar 1 and other origins are 0.\n",
    "#### We will use the dummy variables from the cylinders and year columns to train our 3 models using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "unique_origins = cars[\"origin\"].unique()\n",
    "unique_origins.sort()\n",
    "\n",
    "models = {}\n",
    "features = [c for c in train.columns if c.startswith(\"cyl\") or c.startswith(\"year\")]\n",
    "\n",
    "for origin in unique_origins:\n",
    "    model = LogisticRegression()\n",
    "    X_train = train[features]\n",
    "    y_train = train[\"origin\"] == origin\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    models[origin] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Models\n",
    "#### Now that we have created our models, we can run them through the test dataset and evaluate how they will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_probs = pd.DataFrame(columns = unique_origins)\n",
    "\n",
    "for origin in unique_origins:\n",
    "    X_test = test[features]\n",
    "    testing_probs[origin] = models[origin].predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1         2         3\n",
      "0    0.239793  0.563232  0.217842\n",
      "1    0.314730  0.252581  0.428735\n",
      "2    0.991527  0.008884  0.008943\n",
      "3    0.314730  0.252581  0.428735\n",
      "4    0.257467  0.297368  0.443698\n",
      "5    0.991443  0.008007  0.009880\n",
      "6    0.879833  0.054285  0.081547\n",
      "7    0.284601  0.301124  0.406197\n",
      "8    0.284601  0.301124  0.406197\n",
      "9    0.329410  0.454495  0.219825\n",
      "10   0.879833  0.054285  0.081547\n",
      "11   0.439217  0.332081  0.219673\n",
      "12   0.439217  0.332081  0.219673\n",
      "13   0.979019  0.020506  0.009776\n",
      "14   0.379347  0.327211  0.289725\n",
      "15   0.284601  0.301124  0.406197\n",
      "16   0.439217  0.332081  0.219673\n",
      "17   0.985992  0.010044  0.014370\n",
      "18   0.978911  0.021531  0.009002\n",
      "19   0.284601  0.301124  0.406197\n",
      "20   0.257467  0.297368  0.443698\n",
      "21   0.991660  0.007747  0.010447\n",
      "22   0.905909  0.053712  0.060883\n",
      "23   0.412108  0.268543  0.310212\n",
      "24   0.322411  0.384585  0.291438\n",
      "25   0.893587  0.041531  0.089161\n",
      "26   0.379347  0.327211  0.289725\n",
      "27   0.850745  0.068689  0.082171\n",
      "28   0.239793  0.563232  0.217842\n",
      "29   0.978911  0.021531  0.009002\n",
      "..        ...       ...       ...\n",
      "90   0.257467  0.297368  0.443698\n",
      "91   0.991660  0.007747  0.010447\n",
      "92   0.445593  0.324748  0.229489\n",
      "93   0.239793  0.563232  0.217842\n",
      "94   0.854745  0.089529  0.057786\n",
      "95   0.441660  0.355730  0.202905\n",
      "96   0.595878  0.144144  0.271252\n",
      "97   0.991443  0.008007  0.009880\n",
      "98   0.826557  0.048392  0.129600\n",
      "99   0.990449  0.005925  0.015691\n",
      "100  0.789863  0.137906  0.052834\n",
      "101  0.379347  0.327211  0.289725\n",
      "102  0.903683  0.055427  0.057738\n",
      "103  0.978911  0.021531  0.009002\n",
      "104  0.826557  0.048392  0.129600\n",
      "105  0.314730  0.252581  0.428735\n",
      "106  0.314730  0.252581  0.428735\n",
      "107  0.905909  0.053712  0.060883\n",
      "108  0.445593  0.324748  0.229489\n",
      "109  0.595878  0.144144  0.271252\n",
      "110  0.314730  0.252581  0.428735\n",
      "111  0.329410  0.454495  0.219825\n",
      "112  0.322411  0.384585  0.291438\n",
      "113  0.991443  0.008007  0.009880\n",
      "114  0.441660  0.355730  0.202905\n",
      "115  0.284601  0.301124  0.406197\n",
      "116  0.314730  0.252581  0.428735\n",
      "117  0.985495  0.005456  0.025914\n",
      "118  0.445593  0.324748  0.229489\n",
      "119  0.905909  0.053712  0.060883\n",
      "\n",
      "[120 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(testing_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Origin\n",
    "#### Now that we have trained the models and calculated the probabilities in each origin we can classify each observation. To do so, we want to select the origin with the highest probability of classification fro that observation.\n",
    "#### We will use the idxmax feature toreturn a series where each value corrsponds to the column where the value of probability is maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      3\n",
      "2      1\n",
      "3      3\n",
      "4      3\n",
      "5      1\n",
      "6      1\n",
      "7      3\n",
      "8      3\n",
      "9      2\n",
      "10     1\n",
      "11     1\n",
      "12     1\n",
      "13     1\n",
      "14     1\n",
      "15     3\n",
      "16     1\n",
      "17     1\n",
      "18     1\n",
      "19     3\n",
      "20     3\n",
      "21     1\n",
      "22     1\n",
      "23     1\n",
      "24     2\n",
      "25     1\n",
      "26     1\n",
      "27     1\n",
      "28     2\n",
      "29     1\n",
      "      ..\n",
      "90     3\n",
      "91     1\n",
      "92     1\n",
      "93     2\n",
      "94     1\n",
      "95     1\n",
      "96     1\n",
      "97     1\n",
      "98     1\n",
      "99     1\n",
      "100    1\n",
      "101    1\n",
      "102    1\n",
      "103    1\n",
      "104    1\n",
      "105    3\n",
      "106    3\n",
      "107    1\n",
      "108    1\n",
      "109    1\n",
      "110    3\n",
      "111    2\n",
      "112    2\n",
      "113    1\n",
      "114    1\n",
      "115    3\n",
      "116    3\n",
      "117    1\n",
      "118    1\n",
      "119    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predicted_origins = testing_probs.idxmax(axis=1)\n",
    "print(predicted_origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "#### We have extended the basic logistic regression into a multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
